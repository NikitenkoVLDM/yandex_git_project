Описание проекта ML "обучение с учителем"

Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.
Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. 
Постройте модель с предельно большим значением F1-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте F1-меру на тестовой выборке самостоятельно.
Дополнительно измеряйте AUC-ROC, сравнивайте её значение с F1-мерой.


Инструкция по выполнению проекта

Загрузите и подготовьте данные. Поясните порядок действий.
Исследуйте баланс классов, обучите модель без учёта дисбаланса. Кратко опишите выводы.
Улучшите качество модели, учитывая дисбаланс классов. Обучите разные модели и найдите лучшую. Кратко опишите выводы.
Проведите финальное тестирование.


Описание данных

Признаки

- RowNumber — индекс строки в данных
- CustomerId — уникальный идентификатор клиента
- Surname — фамилия
- CreditScore — кредитный рейтинг
- Geography — страна проживания
- Gender — пол
- Age — возраст
- Tenure — сколько лет человек является клиентом банка
- Balance — баланс на счёте
- NumOfProducts — количество продуктов банка, используемых клиентом
- HasCrCard — наличие кредитной карты
- IsActiveMember — активность клиента
- EstimatedSalary — предполагаемая зарплата
- Целевой признак
- Exited — факт ухода клиента

Данные находятся в файле /datasets/Churn.csv (англ. «отток клиентов»)/


Результаты проекта

- В данных присутствовали пропуски в столбце "Tenure". Пропуски были устранены заглушкой "0"
- Убраны столбцы "RowNumber" и "Surname"
- Выполнено масштабирование
- Выполнено разбитие данных на выборки обучающую, валидационную и тестовую выборки в соотношении 3:1:1
- Категориальные признаки преобразованы к количественным
- Исследован баланс классов
- Изучены модели без учёта дисбаланса
- Лучшая модель: Модель случайного леса с подобранными гиперпараметрами max_depth = 9 и n_estimators = 105, где f1_score на валидационной выборке равно 0.521 Roc_auc на валидационной выборке равно 0.857
- Учтен дисбаланс классов, были рассмотрены методы: взвешиванием классов, увеличением выборки, уменьшением выборки
- Лучший метод дисбаланса классов - взвешивания классов
- Было выполнено тестирование модели на тестовой выборке
- Удалось достичь *F1*-меры на модели случайного леса с гиперпараметрами max_depth = 9 и n_estimators = 105, class_weight='balanced', где f1_score равно 0.635
- Исследована метрика *AUC-ROC* случайного леса, которая равно 0.835